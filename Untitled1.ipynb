{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf7UrhN94ndhp5d/x8e+de",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huyduatop29/Large-Language-Models/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT7axr9pR7Km",
        "outputId": "31d8bc10-f3d6-450d-b374-245be709ffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9uHk1mMSRz7",
        "outputId": "1487b5e3-a09b-4a9b-cd7f-7b4afa628db4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt-2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pyvi.ViTokenizer import tokenize\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Bước 1: Mã hóa các câu bằng mô hình embedding\n",
        "sentences = [\"Bóng đá là môn thể thao vua\"]\n",
        "tokenizer_sent = [tokenize(sent) for sent in sentences]\n",
        "\n",
        "embedding_model = SentenceTransformer('dangvantuan/vietnamese-embedding')\n",
        "embeddings = embedding_model.encode(tokenizer_sent)\n",
        "\n",
        "# Bước 2: Sử dụng GPT-2 để sinh văn bản\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('NlpHUST/gpt2-vietnamese')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('NlpHUST/gpt2-vietnamese')\n",
        "\n",
        "# Lấy câu đầu tiên và sử dụng nó làm prompt\n",
        "prompt = sentences[0]\n",
        "input_ids = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "# Sinh ra văn bản mới dựa trên prompt\n",
        "output = gpt2_model.generate(input_ids,\n",
        "                             max_length=100,\n",
        "                             pad_token_id=gpt2_tokenizer.eos_token_id,\n",
        "                             do_sample=True,\n",
        "                             top_k=40,\n",
        "                             num_beams=5,\n",
        "                             no_repeat_ngram_size=2)\n",
        "\n",
        "generated_text = gpt2_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Generated text:\\n\"\n",
        ", generated_text)\n",
        "\n",
        "# Bước 3: Kết hợp embedding để tinh chỉnh kết quả sinh ra\n",
        "# Sử dụng cosine similarity để đánh giá và chọn kết quả tốt nhất\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Tạo embedding cho văn bản sinh ra\n",
        "generated_embedding = embedding_model.encode([tokenize(generated_text)])\n",
        "\n",
        "# So sánh với các câu gốc để tìm kết quả gần nhất\n",
        "similarity_scores = cosine_similarity(generated_embedding, embeddings)\n",
        "best_match_index = similarity_scores.argmax()\n",
        "\n",
        "print(\"\\nMost similar original sentence based on embedding similarity:\")\n",
        "print(sentences[best_match_index])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpfrH9ESvRZ",
        "outputId": "f3bd9061-592b-4e7c-fa84-0223b7ed3f1d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            " Bóng đá là môn thể thao vua, và có thể nói là đỉnh cao của bóng đá thế giới. Bóng đá luôn là niềm đam mê của rất nhiều người, đặc biệt là các bạn trẻ yêu thích bộ môn này. Tuy nhiên, để có được thành công như ngày hôm nay là cả một quá trình phấn đấu và rèn luyện không ngừng nghỉ của các cầu thủ trẻ.\n",
            "Không phải ngẫu nhiên mà đội tuyển U19 Việt Nam được đánh giá là một trong những ứng viên hàng đầu cho\n",
            "\n",
            "Most similar original sentence based on embedding similarity:\n",
            "Bóng đá là môn thể thao vua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt -neo\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pyvi.ViTokenizer import tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Bước 1: Tải mô hình GPT-Neo và Tokenizer\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"NlpHUST/gpt-neo-vi-small\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"NlpHUST/gpt-neo-vi-small\")\n",
        "\n",
        "# Bước 2: Tạo văn bản bằng GPT-Neo\n",
        "prompt = \"Bóng đá là môn thể thao vua\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "gen_tokens = model.generate(input_ids, do_sample=True, temperature=1.0, max_length=1024)\n",
        "gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n",
        "print(\"Generated text:\\n\", gen_text)\n",
        "\n",
        "# Bước 3: Tải mô hình embedding và mã hóa các câu\n",
        "embedding_model = SentenceTransformer('dangvantuan/vietnamese-embedding')\n",
        "\n",
        "# Tokenize các câu trước khi mã hóa\n",
        "tokenizer_sent = [tokenize(prompt), tokenize(gen_text)]\n",
        "embeddings = embedding_model.encode(tokenizer_sent)\n",
        "\n",
        "# Bước 4: So sánh độ tương đồng cosine giữa embedding của câu gốc và câu sinh ra\n",
        "similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
        "\n",
        "print(\"\\nCosine similarity between prompt and generated text:\", similarity_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1DyRnecVMxT",
        "outputId": "ea7dacb7-08e8-4b8e-885b-752da817096a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            " Bóng đá là môn thể thao vua. Bởi thế chúng tôi cần có sự phối hợp ăn ý giữa HLV trưởng cùng đội ngũ hỗ trợ để tạo thành một đội bóng có uy tín\".\n",
            "HLV Zidane khẳng định sẽ vẫn thi đấu thận trọng ở cả hai trận Siêu kinh điển. Ông nói: \"Các kết quả có được cho thấy chúng tôi đang ở khoảng cách an toàn so với đối thủ. Vì vậy, những gì chúng tôi giành được là những gì chúng tôi có thể đạt được\".\n",
            "Hiện tại, Real Madrid đang xếp thứ 2 La Liga với 25 điểm, kém đội đứng thứ 2 Barcelona 4 điểm và thi đấu nhiều hơn 1 trận. Cuộc đua vô địch La Liga vẫn có sự cạnh tranh gay gắt của 6 đội bóng gồm Sevilla, Chelsea, Sevilla, Barcelona và Atletico Madrid.\n",
            "H.Long\n",
            "\n",
            "Cosine similarity between prompt and generated text: 0.34582728\n"
          ]
        }
      ]
    }
  ]
}